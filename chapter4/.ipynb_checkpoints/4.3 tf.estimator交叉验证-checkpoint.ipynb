{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文将介绍：\n",
    "\n",
    "    数据集使用交叉验证\n",
    "    预定义estimator.LinearClassifier模型\n",
    "    预定义estimator.DNNClassifier模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=6, micro=5, releaselevel='final', serial=0)\n",
      "matplotlib 2.2.2\n",
      "numpy 1.19.2\n",
      "pandas 0.23.0\n",
      "sklearn 0.23.2\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一，加载Titanic数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1，下载Titanic数据集,使用pandas读取并解析数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived     sex   age  n_siblings_spouses  parch      fare   class  \\\n",
      "0           0    male  22.0                   1      0    7.2500   Third   \n",
      "1           1  female  38.0                   1      0   71.2833   First   \n",
      "2           1  female  26.0                   0      0    7.9250   Third   \n",
      "3           1  female  35.0                   1      0   53.1000   First   \n",
      "4           0    male  28.0                   0      0    8.4583   Third   \n",
      "5           0    male   2.0                   3      1   21.0750   Third   \n",
      "6           1  female  27.0                   0      2   11.1333   Third   \n",
      "7           1  female  14.0                   1      0   30.0708  Second   \n",
      "8           1  female   4.0                   1      1   16.7000   Third   \n",
      "9           0    male  20.0                   0      0    8.0500   Third   \n",
      "10          0    male  39.0                   1      5   31.2750   Third   \n",
      "11          0  female  14.0                   0      0    7.8542   Third   \n",
      "12          0    male   2.0                   4      1   29.1250   Third   \n",
      "13          1    male  28.0                   0      0   13.0000  Second   \n",
      "14          0  female  31.0                   1      0   18.0000   Third   \n",
      "15          1  female  28.0                   0      0    7.2250   Third   \n",
      "16          0    male  35.0                   0      0   26.0000  Second   \n",
      "17          1    male  28.0                   0      0   35.5000   First   \n",
      "18          1  female  38.0                   1      5   31.3875   Third   \n",
      "19          0    male  28.0                   0      0    7.2250   Third   \n",
      "20          0    male  19.0                   3      2  263.0000   First   \n",
      "21          1  female  28.0                   0      0    7.8792   Third   \n",
      "22          0    male  28.0                   0      0    7.8958   Third   \n",
      "23          0    male  40.0                   0      0   27.7208   First   \n",
      "24          1  female  28.0                   1      0  146.5208   First   \n",
      "25          1  female  28.0                   0      0    7.7500   Third   \n",
      "26          0    male  66.0                   0      0   10.5000  Second   \n",
      "27          0    male  28.0                   1      0   82.1708   First   \n",
      "28          0    male  42.0                   1      0   52.0000   First   \n",
      "29          1    male  28.0                   0      0    7.2292   Third   \n",
      "..        ...     ...   ...                 ...    ...       ...     ...   \n",
      "597         0    male  35.0                   0      0    7.8958   Third   \n",
      "598         0    male  28.0                   0      1   33.0000  Second   \n",
      "599         1  female  28.0                   1      0   89.1042   First   \n",
      "600         0    male   4.0                   4      2   31.2750   Third   \n",
      "601         1  female  16.0                   0      1   39.4000   First   \n",
      "602         1  female  18.0                   0      1    9.3500   Third   \n",
      "603         1  female  45.0                   1      1  164.8667   First   \n",
      "604         1    male  51.0                   0      0   26.5500   First   \n",
      "605         1  female  24.0                   0      3   19.2583   Third   \n",
      "606         0    male  41.0                   2      0   14.1083   Third   \n",
      "607         0    male  24.0                   0      0   13.0000  Second   \n",
      "608         1  female  42.0                   0      0   13.0000  Second   \n",
      "609         1  female  27.0                   1      0   13.8583  Second   \n",
      "610         0    male  31.0                   0      0   50.4958   First   \n",
      "611         1    male   4.0                   1      1   11.1333   Third   \n",
      "612         0    male  26.0                   0      0    7.8958   Third   \n",
      "613         1  female  47.0                   1      1   52.5542   First   \n",
      "614         0    male  33.0                   0      0    5.0000   First   \n",
      "615         0    male  47.0                   0      0    9.0000   Third   \n",
      "616         1  female  28.0                   1      0   24.0000  Second   \n",
      "617         1  female  15.0                   0      0    7.2250   Third   \n",
      "618         0    male  20.0                   0      0    9.8458   Third   \n",
      "619         0    male  19.0                   0      0    7.8958   Third   \n",
      "620         0    male  28.0                   0      0    7.8958   Third   \n",
      "621         0  female  22.0                   0      0   10.5167   Third   \n",
      "622         0    male  28.0                   0      0   10.5000  Second   \n",
      "623         0    male  25.0                   0      0    7.0500   Third   \n",
      "624         1  female  19.0                   0      0   30.0000   First   \n",
      "625         0  female  28.0                   1      2   23.4500   Third   \n",
      "626         0    male  32.0                   0      0    7.7500   Third   \n",
      "\n",
      "        deck  embark_town alone  \n",
      "0    unknown  Southampton     n  \n",
      "1          C    Cherbourg     n  \n",
      "2    unknown  Southampton     y  \n",
      "3          C  Southampton     n  \n",
      "4    unknown   Queenstown     y  \n",
      "5    unknown  Southampton     n  \n",
      "6    unknown  Southampton     n  \n",
      "7    unknown    Cherbourg     n  \n",
      "8          G  Southampton     n  \n",
      "9    unknown  Southampton     y  \n",
      "10   unknown  Southampton     n  \n",
      "11   unknown  Southampton     y  \n",
      "12   unknown   Queenstown     n  \n",
      "13   unknown  Southampton     y  \n",
      "14   unknown  Southampton     n  \n",
      "15   unknown    Cherbourg     y  \n",
      "16   unknown  Southampton     y  \n",
      "17         A  Southampton     y  \n",
      "18   unknown  Southampton     n  \n",
      "19   unknown    Cherbourg     y  \n",
      "20         C  Southampton     n  \n",
      "21   unknown   Queenstown     y  \n",
      "22   unknown  Southampton     y  \n",
      "23   unknown    Cherbourg     y  \n",
      "24         B    Cherbourg     n  \n",
      "25   unknown   Queenstown     y  \n",
      "26   unknown  Southampton     y  \n",
      "27   unknown    Cherbourg     n  \n",
      "28   unknown  Southampton     n  \n",
      "29   unknown    Cherbourg     y  \n",
      "..       ...          ...   ...  \n",
      "597  unknown    Cherbourg     y  \n",
      "598  unknown  Southampton     n  \n",
      "599        C    Cherbourg     n  \n",
      "600  unknown  Southampton     n  \n",
      "601        D  Southampton     n  \n",
      "602  unknown  Southampton     n  \n",
      "603  unknown  Southampton     n  \n",
      "604        E  Southampton     y  \n",
      "605  unknown    Cherbourg     n  \n",
      "606  unknown  Southampton     n  \n",
      "607  unknown  Southampton     y  \n",
      "608  unknown  Southampton     y  \n",
      "609  unknown    Cherbourg     n  \n",
      "610        A  Southampton     y  \n",
      "611  unknown  Southampton     n  \n",
      "612  unknown  Southampton     y  \n",
      "613        D  Southampton     n  \n",
      "614        B  Southampton     y  \n",
      "615  unknown  Southampton     y  \n",
      "616  unknown    Cherbourg     n  \n",
      "617  unknown    Cherbourg     y  \n",
      "618  unknown  Southampton     y  \n",
      "619  unknown  Southampton     y  \n",
      "620  unknown  Southampton     y  \n",
      "621  unknown  Southampton     y  \n",
      "622  unknown  Southampton     y  \n",
      "623  unknown  Southampton     y  \n",
      "624        B  Southampton     y  \n",
      "625  unknown  Southampton     n  \n",
      "626  unknown   Queenstown     y  \n",
      "\n",
      "[627 rows x 10 columns]\n",
      "     survived     sex    age  n_siblings_spouses  parch     fare   class  \\\n",
      "0           0    male  35.00                   0      0   8.0500   Third   \n",
      "1           0    male  54.00                   0      0  51.8625   First   \n",
      "2           1  female  58.00                   0      0  26.5500   First   \n",
      "3           1  female  55.00                   0      0  16.0000  Second   \n",
      "4           1    male  34.00                   0      0  13.0000  Second   \n",
      "5           1  female  15.00                   0      0   8.0292   Third   \n",
      "6           0  female   8.00                   3      1  21.0750   Third   \n",
      "7           0    male  21.00                   0      0   8.0500   Third   \n",
      "8           0  female  18.00                   2      0  18.0000   Third   \n",
      "9           1  female  19.00                   0      0   7.8792   Third   \n",
      "10          1  female  28.00                   0      0   7.7500   Third   \n",
      "11          0    male  21.00                   0      0   7.8000   Third   \n",
      "12          1  female   5.00                   1      2  27.7500  Second   \n",
      "13          0    male  28.00                   0      0  27.7208   First   \n",
      "14          1  female  29.00                   0      0  10.5000  Second   \n",
      "15          0  female  16.00                   5      2  46.9000   Third   \n",
      "16          0    male  26.00                   1      0  14.4542   Third   \n",
      "17          1  female  17.00                   0      0  10.5000  Second   \n",
      "18          1  female  33.00                   3      0  15.8500   Third   \n",
      "19          0    male  29.00                   0      0   8.0500   Third   \n",
      "20          0    male  20.00                   0      0   7.8542   Third   \n",
      "21          0    male  26.00                   1      2  20.5750   Third   \n",
      "22          1  female  21.00                   0      0   7.6500   Third   \n",
      "23          0    male  38.00                   0      0   7.8958   Third   \n",
      "24          0  female  20.00                   1      0   9.8250   Third   \n",
      "25          0  female   2.00                   4      2  31.2750   Third   \n",
      "26          0    male  21.00                   2      0  73.5000  Second   \n",
      "27          0    male  54.00                   0      1  77.2875   First   \n",
      "28          1    male  12.00                   1      0  11.2417   Third   \n",
      "29          1  female  28.00                   1      1  22.3583   Third   \n",
      "..        ...     ...    ...                 ...    ...      ...     ...   \n",
      "234         0    male  25.00                   0      0   7.2500   Third   \n",
      "235         1  female  18.00                   0      0   7.4958   Third   \n",
      "236         0    male   8.00                   4      1  29.1250   Third   \n",
      "237         1    male   0.42                   0      1   8.5167   Third   \n",
      "238         1    male  27.00                   0      0   6.9750   Third   \n",
      "239         0  female  18.00                   0      0   7.7750   Third   \n",
      "240         0  female   6.00                   4      2  31.2750   Third   \n",
      "241         0    male  43.00                   0      0   6.4500   Third   \n",
      "242         0    male  38.00                   0      0   0.0000   First   \n",
      "243         1  female  27.00                   0      1  12.4750   Third   \n",
      "244         1    male   1.00                   0      2  37.0042  Second   \n",
      "245         1  female  62.00                   0      0  80.0000   First   \n",
      "246         1    male   0.83                   1      1  18.7500  Second   \n",
      "247         1    male  32.00                   0      0  56.4958   Third   \n",
      "248         0    male  20.00                   0      0   7.9250   Third   \n",
      "249         0    male  17.00                   0      0   8.6625   Third   \n",
      "250         0    male  74.00                   0      0   7.7750   Third   \n",
      "251         0  female   9.00                   1      1  15.2458   Third   \n",
      "252         0  female  44.00                   1      0  26.0000  Second   \n",
      "253         0    male  28.00                   0      0   7.2292   Third   \n",
      "254         0    male  21.00                   1      0  11.5000  Second   \n",
      "255         1  female  48.00                   0      0  25.9292   First   \n",
      "256         0  female  28.00                   8      2  69.5500   Third   \n",
      "257         0    male  28.00                   0      0   9.5000   Third   \n",
      "258         1  female  56.00                   0      1  83.1583   First   \n",
      "259         1  female  25.00                   0      1  26.0000  Second   \n",
      "260         0    male  33.00                   0      0   7.8958   Third   \n",
      "261         0  female  39.00                   0      5  29.1250   Third   \n",
      "262         0    male  27.00                   0      0  13.0000  Second   \n",
      "263         1    male  26.00                   0      0  30.0000   First   \n",
      "\n",
      "        deck  embark_town alone  \n",
      "0    unknown  Southampton     y  \n",
      "1          E  Southampton     y  \n",
      "2          C  Southampton     y  \n",
      "3    unknown  Southampton     y  \n",
      "4          D  Southampton     y  \n",
      "5    unknown   Queenstown     y  \n",
      "6    unknown  Southampton     n  \n",
      "7    unknown  Southampton     y  \n",
      "8    unknown  Southampton     n  \n",
      "9    unknown   Queenstown     y  \n",
      "10   unknown   Queenstown     y  \n",
      "11   unknown  Southampton     y  \n",
      "12   unknown  Southampton     n  \n",
      "13   unknown    Cherbourg     y  \n",
      "14         F  Southampton     y  \n",
      "15   unknown  Southampton     n  \n",
      "16   unknown    Cherbourg     n  \n",
      "17   unknown  Southampton     y  \n",
      "18   unknown  Southampton     n  \n",
      "19   unknown  Southampton     y  \n",
      "20   unknown  Southampton     y  \n",
      "21   unknown  Southampton     n  \n",
      "22   unknown  Southampton     y  \n",
      "23   unknown  Southampton     y  \n",
      "24   unknown  Southampton     n  \n",
      "25   unknown  Southampton     n  \n",
      "26   unknown  Southampton     n  \n",
      "27         D  Southampton     n  \n",
      "28   unknown    Cherbourg     n  \n",
      "29         F    Cherbourg     n  \n",
      "..       ...          ...   ...  \n",
      "234  unknown  Southampton     y  \n",
      "235  unknown  Southampton     y  \n",
      "236  unknown   Queenstown     n  \n",
      "237  unknown    Cherbourg     n  \n",
      "238  unknown  Southampton     y  \n",
      "239  unknown  Southampton     y  \n",
      "240  unknown  Southampton     n  \n",
      "241  unknown  Southampton     y  \n",
      "242  unknown  Southampton     y  \n",
      "243        E  Southampton     n  \n",
      "244  unknown    Cherbourg     n  \n",
      "245        B      unknown     y  \n",
      "246  unknown  Southampton     n  \n",
      "247  unknown  Southampton     y  \n",
      "248  unknown  Southampton     y  \n",
      "249  unknown  Southampton     y  \n",
      "250  unknown  Southampton     y  \n",
      "251  unknown    Cherbourg     n  \n",
      "252  unknown  Southampton     n  \n",
      "253  unknown    Cherbourg     y  \n",
      "254  unknown  Southampton     n  \n",
      "255        D  Southampton     y  \n",
      "256  unknown  Southampton     n  \n",
      "257  unknown  Southampton     y  \n",
      "258        C    Cherbourg     n  \n",
      "259  unknown  Southampton     n  \n",
      "260  unknown  Southampton     y  \n",
      "261  unknown   Queenstown     n  \n",
      "262  unknown  Southampton     y  \n",
      "263        C    Cherbourg     y  \n",
      "\n",
      "[264 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "train_file = './data/titanic/train.csv'\n",
    "eval_file = './data/titanic/eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df)\n",
    "print(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2，分离出特征值和目标值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 输出训练和验证标签\n",
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3，使用panda对数值型数据的字段进行统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.feature_column \n",
    "\n",
    "定义特征列。 每个 tf.feature_column 都标识了特征名称、特征类型和任何输入预处理操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二，使用feature_column做数据处理,并转化为tf.data.dataset类型数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1，将\"离散特征\"和\"连续特征\"整合为one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# 1）将特征分为\"离散特征\"和\"连续特征\"两个列表\n",
    "# 离散列\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "# 连续列\n",
    "numeric_columns = ['age', 'fare']\n",
    "# 特征列\n",
    "feature_columns = []\n",
    "\n",
    "\n",
    "# 2）使用tf.feature_column对\"离散特征\"做处理\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    \n",
    "    feature_columns.append(\n",
    "        # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot\n",
    "        tf.feature_column.indicator_column(\n",
    "            # 将一个类别序列，进行hash映射。根据单词的序列顺序，把单词根据index转换成one hot encoding)\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "    \n",
    "# 3）使用tf.feature_column对\"连续特征\"做处理\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross feature: age: [1,2,3,4,5], gender:[male, female]\n",
    "# age_x_gender: [(1, male), (2, male), ..., (5, male), ..., (5, female)]\n",
    "# 100000: 100 -> hash(100000 values) % 100 \n",
    "\n",
    "feature_columns.append(\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.crossed_column(\n",
    "            ['age', 'sex'], hash_bucket_size = 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3，将ndarray数据转化为tf.data.dataset中的BatchDataset类型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=38, shape=(5,), dtype=string, numpy=array([b'male', b'female', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: id=30, shape=(5,), dtype=float64, numpy=array([28., 24., 28., 28., 29.])>, 'n_siblings_spouses': <tf.Tensor: id=36, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 1])>, 'parch': <tf.Tensor: id=37, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0])>, 'fare': <tf.Tensor: id=35, shape=(5,), dtype=float64, numpy=array([ 8.05  , 13.    ,  7.725 ,  7.25  ,  7.0458])>, 'class': <tf.Tensor: id=32, shape=(5,), dtype=string, numpy=array([b'Third', b'Second', b'Third', b'Third', b'Third'], dtype=object)>, 'deck': <tf.Tensor: id=33, shape=(5,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', b'unknown', b'unknown'],\n",
      "      dtype=object)>, 'embark_town': <tf.Tensor: id=34, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Queenstown', b'Southampton',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: id=31, shape=(5,), dtype=string, numpy=array([b'y', b'y', b'y', b'y', b'n'], dtype=object)>} tf.Tensor([0 0 0 0 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    # https://blog.csdn.net/qq_18888869/article/details/94575180\n",
    "    #它的作用是切分传入Tensor的第一个维度，生成相应的dataset。\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df)) \n",
    "    #一个字典，其中键是特征名称，值是包含相应特征数据的张量（或 SparseTensor）\n",
    "    #一个包含一个或多个标签的张量\n",
    "    \n",
    "    if shuffle: \n",
    "        dataset = dataset.shuffle(10000)\n",
    "        \n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, batch_size = 5)\n",
    "# 查看转化后的tf.data.dataset中的一条数据的信息\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、BaselineClassifier、LinearClassifier、DNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'baseline_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000000127B0860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py:206: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-6d93b98af1c1>\", line 8, in <module>\n    baseline_estimator.train(input_fn = lambda : make_dataset(\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1160, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1187, in _train_model_default\n    input_fn, ModeKeys.TRAIN))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1024, in _get_features_and_labels_from_input_fn\n    self._call_input_fn(input_fn, mode))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 65, in parse_input_fn_result\n    result = iterator.get_next()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\", line 2499, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[{{node IteratorGetNext}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6d93b98af1c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     n_classes = 2)\n\u001b[1;32m----> 8\u001b[1;33m baseline_estimator.train(input_fn = lambda : make_dataset(\n\u001b[0m\u001b[0;32m      9\u001b[0m     train_df, y_train, epochs = 100))\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1193\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_creation_timeout_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m         log_step_count_steps=log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[0;32m   1490\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[1;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[0;32m    582\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    723\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \"\"\"\n\u001b[0;32m   1206\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         logging.info(\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    876\u001b[0m       \u001b[1;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m       \u001b[1;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m       \u001b[1;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[1;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[0;32m    294\u001b[0m                            \"init_fn or local_init_op was given\")\n\u001b[0;32m    295\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0minit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-6d93b98af1c1>\", line 8, in <module>\n    baseline_estimator.train(input_fn = lambda : make_dataset(\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1160, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1187, in _train_model_default\n    input_fn, ModeKeys.TRAIN))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1024, in _get_features_and_labels_from_input_fn\n    self._call_input_fn(input_fn, mode))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 65, in parse_input_fn_result\n    result = iterator.get_next()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\", line 2499, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'baseline_model_new_features'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "baseline_estimator = tf.estimator.BaselineClassifier(\n",
    "    model_dir = output_dir,\n",
    "    n_classes = 2)\n",
    "baseline_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find trained model in model_dir: baseline_model_new_features, running initialization to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-12-26T10:58:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-405fcb511f50>\", line 1, in <module>\n    baseline_estimator.evaluate(input_fn = lambda : make_dataset(\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 480, in evaluate\n    name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 522, in _actual_eval\n    return _evaluate()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 504, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1510, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1543, in _call_model_fn_eval\n    input_fn, ModeKeys.EVAL)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1024, in _get_features_and_labels_from_input_fn\n    self._call_input_fn(input_fn, mode))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 65, in parse_input_fn_result\n    result = iterator.get_next()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\", line 2499, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[{{node IteratorGetNext}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-405fcb511f50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m baseline_estimator.evaluate(input_fn = lambda : make_dataset(\n\u001b[0m\u001b[0;32m      2\u001b[0m     eval_df, y_eval, epochs = 1, shuffle = False, batch_size = 20))\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    478\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m           name=name)\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m   def _actual_eval(self,\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[1;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[1;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[0;32m   1616\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1617\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1618\u001b[1;33m         config=self._session_config)\n\u001b[0m\u001b[0;32m   1619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1620\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[1;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m   with monitored_session.MonitoredSession(\n\u001b[1;32m--> 269\u001b[1;33m       session_creator=session_creator, hooks=hooks) as session:\n\u001b[0m\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    723\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \"\"\"\n\u001b[0;32m   1206\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         logging.info(\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    876\u001b[0m       \u001b[1;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m       \u001b[1;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m       \u001b[1;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[1;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[0;32m    294\u001b[0m                            \"init_fn or local_init_op was given\")\n\u001b[0;32m    295\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0minit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[node IteratorGetNext (defined at D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\develop\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\develop\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-405fcb511f50>\", line 1, in <module>\n    baseline_estimator.evaluate(input_fn = lambda : make_dataset(\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 480, in evaluate\n    name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 522, in _actual_eval\n    return _evaluate()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 504, in _evaluate\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1510, in _evaluate_build_graph\n    self._call_model_fn_eval(input_fn, self.config))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1543, in _call_model_fn_eval\n    input_fn, ModeKeys.EVAL)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1024, in _get_features_and_labels_from_input_fn\n    self._call_input_fn(input_fn, mode))\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 65, in parse_input_fn_result\n    result = iterator.get_next()\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\", line 2499, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 793, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3360, in create_op\n    attrs, op_def, compute_device)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3429, in _create_op_internal\n    op_def=op_def)\n  File \"D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1751, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "baseline_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False, batch_size = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'linear_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000000191F4160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From D:\\develop\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into linear_model_new_features\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 480.769\n",
      "INFO:tensorflow:loss = 0.4621312, step = 100 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1000\n",
      "INFO:tensorflow:loss = 0.4331709, step = 200 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.578\n",
      "INFO:tensorflow:loss = 0.25085384, step = 300 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.39\n",
      "INFO:tensorflow:loss = 0.37339935, step = 400 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1000\n",
      "INFO:tensorflow:loss = 0.34445316, step = 500 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.999\n",
      "INFO:tensorflow:loss = 0.32375947, step = 600 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.098\n",
      "INFO:tensorflow:loss = 0.4292472, step = 700 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.381\n",
      "INFO:tensorflow:loss = 0.43431467, step = 800 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.383\n",
      "INFO:tensorflow:loss = 0.43554544, step = 900 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.098\n",
      "INFO:tensorflow:loss = 0.3088675, step = 1000 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.1\n",
      "INFO:tensorflow:loss = 0.36954835, step = 1100 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.39\n",
      "INFO:tensorflow:loss = 0.43424028, step = 1200 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.459\n",
      "INFO:tensorflow:loss = 0.3482963, step = 1300 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.098\n",
      "INFO:tensorflow:loss = 0.36305755, step = 1400 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.431\n",
      "INFO:tensorflow:loss = 0.32591933, step = 1500 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.092\n",
      "INFO:tensorflow:loss = 0.5975489, step = 1600 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.1\n",
      "INFO:tensorflow:loss = 0.3594486, step = 1700 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.874\n",
      "INFO:tensorflow:loss = 0.28575233, step = 1800 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.098\n",
      "INFO:tensorflow:loss = 0.5488287, step = 1900 (0.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into linear_model_new_features\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.26202914.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x191c4710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output_dir = 'linear_model_new_features'\n",
    "if not os.path.exists(linear_output_dir):\n",
    "    os.mkdir(linear_output_dir)\n",
    "    \n",
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    model_dir = linear_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns = feature_columns)\n",
    "\n",
    "linear_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-12-26T10:58:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model_new_features\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-12-26-10:58:57\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.8030303, accuracy_baseline = 0.625, auc = 0.8580655, auc_precision_recall = 0.7715421, average_loss = 0.45644423, global_step = 1960, label/mean = 0.375, loss = 0.44113424, precision = 0.7281553, prediction/mean = 0.3937147, recall = 0.75757575\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: linear_model_new_features\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8030303,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.8580655,\n",
       " 'auc_precision_recall': 0.7715421,\n",
       " 'average_loss': 0.45644423,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.44113424,\n",
       " 'precision': 0.7281553,\n",
       " 'prediction/mean': 0.3937147,\n",
       " 'recall': 0.75757575,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './dnn_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000001CBF21D0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./dnn_model_new_features\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4.4053864, step = 0\n",
      "INFO:tensorflow:global_step/sec: 448.431\n",
      "INFO:tensorflow:loss = 0.47755027, step = 100 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.401\n",
      "INFO:tensorflow:loss = 0.44774133, step = 200 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.88\n",
      "INFO:tensorflow:loss = 0.5935021, step = 300 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.295\n",
      "INFO:tensorflow:loss = 0.4474424, step = 400 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.268\n",
      "INFO:tensorflow:loss = 0.27023315, step = 500 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.3\n",
      "INFO:tensorflow:loss = 0.2796682, step = 600 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.194\n",
      "INFO:tensorflow:loss = 0.29870808, step = 700 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.576\n",
      "INFO:tensorflow:loss = 0.18932767, step = 800 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.194\n",
      "INFO:tensorflow:loss = 0.24391529, step = 900 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.451\n",
      "INFO:tensorflow:loss = 0.34000704, step = 1000 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.336\n",
      "INFO:tensorflow:loss = 0.17200042, step = 1100 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.93\n",
      "INFO:tensorflow:loss = 0.16607308, step = 1200 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.027\n",
      "INFO:tensorflow:loss = 0.21318589, step = 1300 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.284\n",
      "INFO:tensorflow:loss = 0.22646433, step = 1400 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.88\n",
      "INFO:tensorflow:loss = 0.24988845, step = 1500 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.424\n",
      "INFO:tensorflow:loss = 0.18576002, step = 1600 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.288\n",
      "INFO:tensorflow:loss = 0.094209895, step = 1700 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.238\n",
      "INFO:tensorflow:loss = 0.16401821, step = 1800 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.117\n",
      "INFO:tensorflow:loss = 0.0785555, step = 1900 (0.160 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into ./dnn_model_new_features\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2589701.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1cbe5ac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_output_dir = './dnn_model_new_features'\n",
    "if not os.path.exists(dnn_output_dir):\n",
    "    os.mkdir(dnn_output_dir)\n",
    "    \n",
    "dnn_estimator = tf.estimator.DNNClassifier(\n",
    "    model_dir = dnn_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units = [128, 128],\n",
    "    activation_fn = tf.nn.relu,\n",
    "    optimizer = 'Adam')\n",
    "\n",
    "dnn_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-12-26T10:59:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model_new_features\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-12-26-10:59:18\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.6931818, accuracy_baseline = 0.625, auc = 0.8374349, auc_precision_recall = 0.7549721, average_loss = 0.9985205, global_step = 1960, label/mean = 0.375, loss = 0.9566963, precision = 0.55921054, prediction/mean = 0.58450794, recall = 0.85858583\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: ./dnn_model_new_features\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6931818,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.8374349,\n",
       " 'auc_precision_recall': 0.7549721,\n",
       " 'average_loss': 0.9985205,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.9566963,\n",
       " 'precision': 0.55921054,\n",
       " 'prediction/mean': 0.58450794,\n",
       " 'recall': 0.85858583,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.evaluate(input_fn = lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1, shuffle = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：使用交叉验证的数据集可以增强数据的相关性，也可以增强模型的预测率（准确率、召回率等），\n",
    "但是不一定对所有模型都可以，提高了LinearClassifier的预测,降低了DNNClassifier的预测；\n",
    "所以使用交叉验证需要考虑模型的适配性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
